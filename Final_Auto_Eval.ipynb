{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHMRnAKpcjdR"
   },
   "source": [
    "**Evaluation with GPT2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3Qh8JWEDGm-",
    "outputId": "caf00875-4088-46c4-a4d9-dad15abb16b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpjvliYQ1p0j",
    "outputId": "77d5a5d4-7a55-48d1-9ef2-9112a5f76608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
      "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
      "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,140 kB]\n",
      "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,384 kB]\n",
      "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,844 kB]\n",
      "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,697 kB]\n",
      "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
      "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
      "Fetched 21.9 MB in 5s (4,576 kB/s)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "36 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libxt-dev libxtst6 libxxf86dga1\n",
      "  openjdk-17-jdk-headless openjdk-17-jre openjdk-17-jre-headless x11-utils\n",
      "Suggested packages:\n",
      "  libxt-doc openjdk-17-demo openjdk-17-source visualvm libnss-mdns\n",
      "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
      "  | fonts-wqy-zenhei fonts-indic mesa-utils\n",
      "The following NEW packages will be installed:\n",
      "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libxt-dev libxtst6 libxxf86dga1 openjdk-17-jdk\n",
      "  openjdk-17-jdk-headless openjdk-17-jre openjdk-17-jre-headless x11-utils\n",
      "0 upgraded, 12 newly installed, 0 to remove and 36 not upgraded.\n",
      "Need to get 125 MB of archives.\n",
      "After this operation, 287 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre-headless amd64 17.0.14+7-1~22.04.1 [48.3 MB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre amd64 17.0.14+7-1~22.04.1 [232 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk-headless amd64 17.0.14+7-1~22.04.1 [71.3 MB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk amd64 17.0.14+7-1~22.04.1 [1,521 kB]\n",
      "Fetched 125 MB in 2s (72.7 MB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 12.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "(Reading database ... 126332 files and directories currently installed.)\n",
      "Preparing to unpack .../00-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
      "Selecting previously unselected package fonts-dejavu-extra.\n",
      "Preparing to unpack .../01-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
      "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
      "Selecting previously unselected package libxtst6:amd64.\n",
      "Preparing to unpack .../02-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
      "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
      "Selecting previously unselected package libxxf86dga1:amd64.\n",
      "Preparing to unpack .../03-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
      "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
      "Selecting previously unselected package x11-utils.\n",
      "Preparing to unpack .../04-x11-utils_7.7+5build2_amd64.deb ...\n",
      "Unpacking x11-utils (7.7+5build2) ...\n",
      "Selecting previously unselected package libatk-wrapper-java.\n",
      "Preparing to unpack .../05-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
      "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
      "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
      "Preparing to unpack .../06-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
      "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
      "Selecting previously unselected package libxt-dev:amd64.\n",
      "Preparing to unpack .../07-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
      "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
      "Selecting previously unselected package openjdk-17-jre-headless:amd64.\n",
      "Preparing to unpack .../08-openjdk-17-jre-headless_17.0.14+7-1~22.04.1_amd64.deb ...\n",
      "Unpacking openjdk-17-jre-headless:amd64 (17.0.14+7-1~22.04.1) ...\n",
      "Selecting previously unselected package openjdk-17-jre:amd64.\n",
      "Preparing to unpack .../09-openjdk-17-jre_17.0.14+7-1~22.04.1_amd64.deb ...\n",
      "Unpacking openjdk-17-jre:amd64 (17.0.14+7-1~22.04.1) ...\n",
      "Selecting previously unselected package openjdk-17-jdk-headless:amd64.\n",
      "Preparing to unpack .../10-openjdk-17-jdk-headless_17.0.14+7-1~22.04.1_amd64.deb ...\n",
      "Unpacking openjdk-17-jdk-headless:amd64 (17.0.14+7-1~22.04.1) ...\n",
      "Selecting previously unselected package openjdk-17-jdk:amd64.\n",
      "Preparing to unpack .../11-openjdk-17-jdk_17.0.14+7-1~22.04.1_amd64.deb ...\n",
      "Unpacking openjdk-17-jdk:amd64 (17.0.14+7-1~22.04.1) ...\n",
      "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
      "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
      "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
      "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
      "Setting up openjdk-17-jre-headless:amd64 (17.0.14+7-1~22.04.1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
      "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
      "Setting up x11-utils (7.7+5build2) ...\n",
      "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
      "Setting up openjdk-17-jre:amd64 (17.0.14+7-1~22.04.1) ...\n",
      "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
      "Setting up openjdk-17-jdk-headless:amd64 (17.0.14+7-1~22.04.1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
      "Setting up openjdk-17-jdk:amd64 (17.0.14+7-1~22.04.1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
      "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in manual mode\n",
      "openjdk version \"17.0.14\" 2025-01-21\n",
      "OpenJDK Runtime Environment (build 17.0.14+7-Ubuntu-122.04.1)\n",
      "OpenJDK 64-Bit Server VM (build 17.0.14+7-Ubuntu-122.04.1, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "!sudo apt update\n",
    "!sudo apt install openjdk-17-jdk -y\n",
    "!sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/java-17-openjdk-amd64/bin/java 1\n",
    "!sudo update-alternatives --set java /usr/lib/jvm/java-17-openjdk-amd64/bin/java\n",
    "\n",
    "# Verify the version\n",
    "!java -version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "MVXYXmx4cjCx",
    "outputId": "40598c7b-5554-4a20-b9c4-26b9e3e9cfbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: language-tool-python in /usr/local/lib/python3.11/dist-packages (2.9.3)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (2.32.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (5.9.5)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (0.10.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized all components\n",
      "Reading file: /content/drive/MyDrive/MC_Data/generated_items/GPT.xlsx\n",
      "Processing sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 2755/3509 [1:55:10<03:27,  3.64it/s]"
     ]
    }
   ],
   "source": [
    "!pip install language-tool-python spacy transformers torch nltk pandas openpyxl tqdm\n",
    "import spacy\n",
    "import language_tool_python\n",
    "import numpy as np\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Download required data\n",
    "nltk.download('punkt')\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    !python -m spacy download en_core_web_sm\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "class GrammarEvaluator:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the grammar evaluator with necessary tools\"\"\"\n",
    "        try:\n",
    "            self.language_tool = language_tool_python.LanguageTool('en-US')\n",
    "            self.nlp = spacy.load('en_core_web_sm')\n",
    "            self.gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "            self.gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            self.gpt2_model.to(self.device)\n",
    "            print(\"Successfully initialized all components\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing components: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def calculate_error_density(self, text):\n",
    "        try:\n",
    "            matches = self.language_tool.check(text)\n",
    "            word_count = len(text.split())\n",
    "            error_count = len(matches)\n",
    "            error_details = []\n",
    "            for match in matches:\n",
    "                error_details.append({\n",
    "                    'message': match.message,\n",
    "                    'replacements': match.replacements[:3],\n",
    "                    'context': match.context,\n",
    "                    'category': match.category\n",
    "                })\n",
    "            return {\n",
    "                'error_count': error_count,\n",
    "                'word_count': word_count,\n",
    "                'error_density': (error_count / word_count * 100) if word_count > 0 else 0,\n",
    "                'error_details': error_details\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating error density: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_complexity_metrics(self, text):\n",
    "        try:\n",
    "            doc = self.nlp(text)\n",
    "            words = [token.text for token in doc if not token.is_punct]\n",
    "            sentences = list(doc.sents)\n",
    "\n",
    "            def get_depth(token):\n",
    "                return 1 + max([get_depth(child) for child in token.children], default=0)\n",
    "\n",
    "            metrics = {\n",
    "                'avg_word_length': np.mean([len(word) for word in words]) if words else 0,\n",
    "                'avg_sentence_length': np.mean([len([token for token in sent if not token.is_punct])\n",
    "                                             for sent in sentences]) if sentences else 0,\n",
    "                'unique_words_ratio': len(set(words)) / len(words) if words else 0,\n",
    "                'pos_distribution': dict(nltk.FreqDist([token.pos_ for token in doc])),\n",
    "                'avg_syntax_depth': np.mean([get_depth(sent.root) for sent in sentences]) if sentences else 0\n",
    "            }\n",
    "            return metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating complexity metrics: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_readability(self, text):\n",
    "        try:\n",
    "            def count_syllables(word):\n",
    "                word = word.lower()\n",
    "                count = 0\n",
    "                vowels = 'aeiouy'\n",
    "                if word[0] in vowels:\n",
    "                    count += 1\n",
    "                for index in range(1, len(word)):\n",
    "                    if word[index] in vowels and word[index-1] not in vowels:\n",
    "                        count += 1\n",
    "                if word.endswith('e'):\n",
    "                    count -= 1\n",
    "                if count == 0:\n",
    "                    count += 1\n",
    "                return count\n",
    "\n",
    "            doc = self.nlp(text)\n",
    "            words = [token.text for token in doc if not token.is_punct]\n",
    "            sentences = list(doc.sents)\n",
    "\n",
    "            word_count = len(words)\n",
    "            sentence_count = len(sentences)\n",
    "            syllable_count = sum(count_syllables(word) for word in words)\n",
    "            complex_words = len([word for word in words if count_syllables(word) >= 3])\n",
    "\n",
    "            if word_count > 0 and sentence_count > 0:\n",
    "                flesch = 206.835 - 1.015 * (word_count/sentence_count) - 84.6 * (syllable_count/word_count)\n",
    "                gunning_fog = 0.4 * ((word_count/sentence_count) + 100 * (complex_words/word_count))\n",
    "            else:\n",
    "                flesch = 0\n",
    "                gunning_fog = 0\n",
    "\n",
    "            return {\n",
    "                'flesch_reading_ease': flesch,\n",
    "                'gunning_fog_index': gunning_fog,\n",
    "                'avg_syllables_per_word': syllable_count/word_count if word_count > 0 else 0,\n",
    "                'complex_word_ratio': complex_words/word_count if word_count > 0 else 0\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating readability: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_perplexity(self, text):\n",
    "        try:\n",
    "            encodings = self.gpt2_tokenizer(text, return_tensors='pt')\n",
    "            input_ids = encodings.input_ids.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.gpt2_model(input_ids, labels=input_ids)\n",
    "                loss = outputs.loss\n",
    "            return torch.exp(loss).item()\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating perplexity: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def evaluate(self, text):\n",
    "        try:\n",
    "            error_metrics = self.calculate_error_density(text)\n",
    "            complexity_metrics = self.calculate_complexity_metrics(text)\n",
    "            readability_metrics = self.calculate_readability(text)\n",
    "            perplexity = self.calculate_perplexity(text)\n",
    "\n",
    "            error_score = max(0, 1 - error_metrics['error_density']/10)\n",
    "            complexity_score = min(1, complexity_metrics['avg_syntax_depth']/5)\n",
    "            readability_score = min(1, max(0, readability_metrics['flesch_reading_ease']/100))\n",
    "            perplexity_score = max(0, 1 - (perplexity-20)/100)\n",
    "\n",
    "            final_score = (error_score * 0.4 +\n",
    "                         complexity_score * 0.2 +\n",
    "                         readability_score * 0.2 +\n",
    "                         perplexity_score * 0.2) * 100\n",
    "\n",
    "            return {\n",
    "                'final_score': final_score,\n",
    "                'subscores': {\n",
    "                    'grammar': error_score * 100,\n",
    "                    'complexity': complexity_score * 100,\n",
    "                    'readability': readability_score * 100,\n",
    "                    'fluency': perplexity_score * 100\n",
    "                },\n",
    "                'detailed_metrics': {\n",
    "                    'error_metrics': error_metrics,\n",
    "                    'complexity_metrics': complexity_metrics,\n",
    "                    'readability_metrics': readability_metrics,\n",
    "                    'perplexity': perplexity\n",
    "                }\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error in evaluation: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# Process Excel file\n",
    "input_file = '/content/drive/MyDrive/MC_Data/generated_items/GPT.xlsx'\n",
    "output_file = '/content/drive/MyDrive/MC_Data/generated_items/evaluation/All_str_GPT.xlsx'\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = GrammarEvaluator()\n",
    "\n",
    "try:\n",
    "    # Read Excel file\n",
    "    print(f\"Reading file: {input_file}\")\n",
    "    df = pd.read_excel(input_file)\n",
    "\n",
    "    # Concatenate specified columns\n",
    "    print(\"Processing sentences...\")\n",
    "    df['combined_text'] = df[['question']].fillna('').astype(str).apply(' '.join, axis=1)\n",
    "    df['combined_text'] = df['combined_text'].astype(str).str.capitalize()\n",
    "    df['question'] = df['question'].astype(str).str.capitalize()\n",
    "\n",
    "    results = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row['combined_text'].strip()\n",
    "        if text:\n",
    "            evaluation = evaluator.evaluate(text)\n",
    "            if evaluation:\n",
    "                results.append({\n",
    "                    'Row': idx + 2,  # Excel row number (1-based + header)\n",
    "                    'Prompting_strategy':row.get('strategy', ''),\n",
    "                    'Question_Type':row.get('question_type', ''),\n",
    "                    'Question':row.get('question',''),\n",
    "                    'Correct_Answer': row.get('correct_answer', ''),\n",
    "                    'Choice_1': row.get('choice_a', ''),\n",
    "                    'Choice_2': row.get('choice_b', ''),\n",
    "                    'Choice_3': row.get('choice_c', ''),\n",
    "                    'Word_Difficulty': row.get('word_difficulty', ''),\n",
    "                    'Task_Difficulty': row.get('task_difficulty', ''),\n",
    "                    'Text': text,\n",
    "                    'Overall_Score': evaluation['final_score'],\n",
    "                    'Grammar_Score': evaluation['subscores']['grammar'],\n",
    "                    'Complexity_Score': evaluation['subscores']['complexity'],\n",
    "                    'Readability_Score': evaluation['subscores']['readability'],\n",
    "                    'Fluency_Score': evaluation['subscores']['fluency'],\n",
    "                    'Error_Count': evaluation['detailed_metrics']['error_metrics']['error_count'],\n",
    "                    'Errors': '; '.join([error['message'] for error in\n",
    "                                       evaluation['detailed_metrics']['error_metrics']['error_details']])\n",
    "                })\n",
    "\n",
    "    # Create and save results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_excel(output_file, index=False)\n",
    "\n",
    "    print(\"\\nProcessing complete!\")\n",
    "    print(f\"Total sentences processed: {len(results_df)}\")\n",
    "    print(f\"Average score: {results_df['Overall_Score'].mean():.2f}\")\n",
    "    print(f\"Total errors found: {results_df['Error_Count'].sum()}\")\n",
    "\n",
    "    # Display sample results\n",
    "    print(\"\\nSample results (first 5 rows):\")\n",
    "    print(results_df[['Row', 'Overall_Score', 'Error_Count', 'Errors']].head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9oYSaMnz27_8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
